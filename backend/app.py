from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from model.infer import run_inference
from utils.analysis import analyze_results
from utils.heatmap import generate_heatmap
from db import init_db, save_analysis, get_history, get_statistics
import os
from dotenv import load_dotenv
from openai import OpenAI


# ============================================
# ğŸ”¥ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
# ============================================
load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
if not os.getenv("OPENAI_API_KEY"):
    print("âš ï¸ WARNING: OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")


# ============================================
# Flask ì´ˆê¸° ì„¤ì •
# ============================================
app = Flask(__name__)

CORS(
    app,
    resources={r"/*": {"origins": "http://localhost:3000"}},
    supports_credentials=True
)

UPLOAD_FOLDER = 'uploads'
RESULT_FOLDER = 'results'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(RESULT_FOLDER, exist_ok=True)


# DB ì´ˆê¸°í™”
init_db()


@app.route('/')
def home():
    return jsonify({"message": "AI Organizer API is running"}), 200


# ============================================
# ğŸ”¥ ChatGPT ì •ë¦¬ ì½”ì¹­ ìƒì„± í•¨ìˆ˜ (ìµœì‹  API í˜¸í™˜)
# ============================================
def generate_ai_advice(detections, score):
    """ YOLO ê°ì§€ ê²°ê³¼ ê¸°ë°˜ìœ¼ë¡œ ChatGPT ì •ë¦¬ ì½”ì¹­ ìƒì„± """

    try:
        detected_items = ", ".join([d["name"] for d in detections]) or "ì•„ë¬´ê²ƒë„ ê°ì§€ë˜ì§€ ì•ŠìŒ"

        prompt = f"""
ë„ˆëŠ” ìµœê³  ìˆ˜ì¤€ì˜ ë°© ì •ë¦¬ ì „ë¬¸ê°€ì•¼.

ì•„ë˜ëŠ” YOLOê°€ ê°ì§€í•œ ë°©ì˜ ë¬¼ê±´ ë¦¬ìŠ¤íŠ¸ì•¼:
[{detected_items}]

ì´ ë°©ì˜ ì •ë¦¬ ì ìˆ˜ëŠ” {score}ì ì´ì•¼.

ì´ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒì„ 5~8ì¤„ë¡œ ê°„ê²°í•˜ê²Œ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì¤˜.
1) ë°© ì „ì²´ ìƒíƒœ ìš”ì•½
2) ì •ë¦¬ ìš°ì„ ìˆœìœ„ TOP 3
3) ë¬¼ê±´ë“¤ì„ ì–´ë””ì— ì •ë¦¬í•˜ë©´ ì¢‹ì€ì§€ (ì±…ìƒ, ì„œë, ì˜·ì¥ ë“±)
4) ì „ì²´ì ì¸ ì •ë¦¬ ë£¨í‹´ ì œì•ˆ
"""

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ë°© ì •ë¦¬ ì „ë¬¸ê°€ë‹¤."},
                {"role": "user", "content": prompt}
            ]
        )

        advice = response.choices[0].message.content
        return advice

    except Exception as e:
        print("ChatGPT ì˜¤ë¥˜:", e)
        return "ì •ë¦¬ ì¡°ì–¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."


# ============================================
# ğŸ¯ ë©”ì¸ ì´ë¯¸ì§€ ë¶„ì„ API
# ============================================
@app.route('/analyze', methods=['POST'])
def analyze_image():

    # íŒŒì¼ ì²´í¬
    if 'image' not in request.files:
        return jsonify({'error': 'No image uploaded'}), 400

    file = request.files['image']
    filepath = os.path.join(UPLOAD_FOLDER, file.filename)
    file.save(filepath)

    # 1) YOLO ëª¨ë¸ ì¶”ë¡ 
    try:
        detections, result_img_path = run_inference(filepath, RESULT_FOLDER)
    except Exception as e:
        return jsonify({'error': f'Model inference failed: {str(e)}'}), 500

    # 2) ì ìˆ˜ ë° ë¬¸ì œ ë¶„ì„
    try:
        report = analyze_results(detections)
    except Exception as e:
        return jsonify({'error': f'Analysis failed: {str(e)}'}), 500

    # 3) íˆíŠ¸ë§µ ìƒì„±
    heatmap_path = None
    if detections:
        try:
            heatmap_filename = 'heatmap_' + file.filename
            heatmap_full_path = os.path.join(RESULT_FOLDER, heatmap_filename)
            generate_heatmap(filepath, detections, heatmap_full_path)
            heatmap_path = f"/results/{heatmap_filename}"
        except Exception as e:
            print("íˆíŠ¸ë§µ ìƒì„± ì‹¤íŒ¨:", e)

    # 4) ğŸ”¥ ChatGPT ì •ë¦¬ ì¡°ì–¸ ìƒì„±
    ai_advice = generate_ai_advice(detections, report["score"])

    # 5) DB ì €ì¥
    try:
        save_analysis(
            score=report['score'],
            detections=detections,
            report=report,
            image_name=file.filename
        )
    except Exception as e:
        print("DB ì €ì¥ ì‹¤íŒ¨:", e)

    # 6) ìµœì¢… ì‘ë‹µ ë°ì´í„° êµ¬ì„±
    response_data = {
        "status": "success",
        "detections": detections,
        "report": report,
        "ai_advice": ai_advice,
        "result_image": f"/results/{os.path.basename(result_img_path)}"
    }

    if heatmap_path:
        response_data["heatmap_image"] = heatmap_path

    return jsonify(response_data)


# ============================================
# ğŸ“Œ ë¶„ì„ ê¸°ë¡/API
# ============================================
@app.route('/history', methods=['GET'])
def get_analysis_history():
    try:
        limit = request.args.get('limit', 10, type=int)
        limit = min(limit, 50)
        history = get_history(limit)
        return jsonify({
            "status": "success",
            "count": len(history),
            "history": history
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/statistics', methods=['GET'])
def get_stats():
    try:
        stats = get_statistics()
        return jsonify({
            "status": "success",
            "statistics": stats
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500


# ============================================
# ğŸ“Œ ê²°ê³¼ ì´ë¯¸ì§€ ì„œë¹™
# ============================================
@app.route('/results/<path:filename>')
def serve_result_image(filename):
    return send_from_directory(RESULT_FOLDER, filename)


# ============================================
# ì„œë²„ ì‹¤í–‰
# ============================================
if __name__ == "__main__":
    app.run(debug=True, host="0.0.0.0", port=5000)
