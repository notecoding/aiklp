# backend/app.py
"""
ì™„ì „ ê°œì„ ëœ Flask ë°±ì—”ë“œ
- 3ê°€ì§€ AI ê°œì„ ì‚¬í•­ ëª¨ë‘ í†µí•©
"""
from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from model.infer import run_inference
from utils.analysis import analyze_results
from utils.heatmap import generate_heatmap
from utils.room_segmentation import visualize_room_zones, calculate_area_coverage
from utils.stacking_visualizer import visualize_stacks
from utils.object_tracker import get_tracker
from db import init_db, save_analysis, get_history, get_statistics
import os
from dotenv import load_dotenv
from openai import OpenAI

# ============================================
# í™˜ê²½ ë³€ìˆ˜ ë° ì´ˆê¸° ì„¤ì •
# ============================================
load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
if not os.getenv("OPENAI_API_KEY"):
    print("âš ï¸ WARNING: OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")

app = Flask(__name__)

CORS(
    app,
    resources={r"/*": {"origins": "http://localhost:3000"}},
    supports_credentials=True
)

UPLOAD_FOLDER = 'uploads'
RESULT_FOLDER = 'results'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(RESULT_FOLDER, exist_ok=True)

# DB ì´ˆê¸°í™”
init_db()


@app.route('/')
def home():
    return jsonify({"message": "AI Organizer API is running - Full Enhanced Version"}), 200


# ============================================
# ChatGPT ì¡°ì–¸ ìƒì„± (ê¸°ì¡´)
# ============================================
def generate_ai_advice(detections, score):
    """YOLO ê°ì§€ ê²°ê³¼ ê¸°ë°˜ìœ¼ë¡œ ChatGPT ì •ë¦¬ ì½”ì¹­ ìƒì„±"""
    try:
        detected_items = ", ".join([d["name"] for d in detections]) or "ì•„ë¬´ê²ƒë„ ê°ì§€ë˜ì§€ ì•ŠìŒ"

        prompt = f"""
ë„ˆëŠ” ìµœê³  ìˆ˜ì¤€ì˜ ë°© ì •ë¦¬ ì „ë¬¸ê°€ì•¼.

ì•„ë˜ëŠ” YOLOê°€ ê°ì§€í•œ ë°©ì˜ ë¬¼ê±´ ë¦¬ìŠ¤íŠ¸ì•¼:
[{detected_items}]

ì´ ë°©ì˜ ì •ë¦¬ ì ìˆ˜ëŠ” {score}ì ì´ì•¼.

ì´ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒì„ 5~8ì¤„ë¡œ ê°„ê²°í•˜ê²Œ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì¤˜.
1) ë°© ì „ì²´ ìƒíƒœ ìš”ì•½
2) ì •ë¦¬ ìš°ì„ ìˆœìœ„ TOP 3
3) ë¬¼ê±´ë“¤ì„ ì–´ë””ì— ì •ë¦¬í•˜ë©´ ì¢‹ì€ì§€ (ì±…ìƒ, ì„œë, ì˜·ì¥ ë“±)
4) ì „ì²´ì ì¸ ì •ë¦¬ ë£¨í‹´ ì œì•ˆ
"""

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ë°© ì •ë¦¬ ì „ë¬¸ê°€ë‹¤."},
                {"role": "user", "content": prompt}
            ]
        )

        advice = response.choices[0].message.content
        return advice

    except Exception as e:
        print("ChatGPT ì˜¤ë¥˜:", e)
        return "ì •ë¦¬ ì¡°ì–¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."


# ============================================
# ğŸ”¥ ë©”ì¸ ë¶„ì„ API (ì™„ì „ ê°œì„ )
# ============================================
@app.route('/analyze', methods=['POST'])
def analyze_image():
    
    # íŒŒì¼ ì²´í¬
    if 'image' not in request.files:
        return jsonify({'error': 'No image uploaded'}), 400

    file = request.files['image']
    filepath = os.path.join(UPLOAD_FOLDER, file.filename)
    file.save(filepath)

    # 1ï¸âƒ£ ì™„ì „ ê°œì„ ëœ ì¶”ë¡  (Segmentation + ìŒ“ì„ íƒì§€ í¬í•¨)
    try:
        detections, result_img_path, room_masks, stacks = run_inference(filepath, RESULT_FOLDER)
        print(f"âœ… ì¶”ë¡  ì™„ë£Œ: {len(detections)}ê°œ ê°ì²´, {len(stacks)}ê°œ ìŒ“ì„")
    except Exception as e:
        return jsonify({'error': f'Model inference failed: {str(e)}'}), 500

    # 2ï¸âƒ£ ë¶„ì„ (ìŒ“ì„ ì •ë³´ í¬í•¨)
    try:
        report = analyze_results(detections)
        print(f"âœ… ë¶„ì„ ì™„ë£Œ: ì ìˆ˜ {report['score']}ì ")
    except Exception as e:
        return jsonify({'error': f'Analysis failed: {str(e)}'}), 500

    # 3ï¸âƒ£ íˆíŠ¸ë§µ ìƒì„± (ê¸°ì¡´)
    heatmap_path = None
    if detections:
        try:
            heatmap_filename = 'heatmap_' + file.filename
            heatmap_full_path = os.path.join(RESULT_FOLDER, heatmap_filename)
            generate_heatmap(filepath, detections, heatmap_full_path)
            heatmap_path = f"/results/{heatmap_filename}"
            print("âœ… íˆíŠ¸ë§µ ìƒì„± ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ íˆíŠ¸ë§µ ìƒì„± ì‹¤íŒ¨: {e}")

    # 4ï¸âƒ£ êµ¬ì—­ ì‹œê°í™” ìƒì„± (Segmentation)
    zone_visualization_path = None
    area_coverage = None
    
    if room_masks is not None:
        try:
            zone_filename = 'zones_' + file.filename
            zone_full_path = os.path.join(RESULT_FOLDER, zone_filename)
            visualize_room_zones(filepath, room_masks, zone_full_path)
            zone_visualization_path = f"/results/{zone_filename}"
            
            area_coverage = calculate_area_coverage(room_masks)
            print("âœ… êµ¬ì—­ ì‹œê°í™” ìƒì„± ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ êµ¬ì—­ ì‹œê°í™” ì‹¤íŒ¨: {e}")

    # 5ï¸âƒ£ ìŒ“ì„ ì‹œê°í™” ìƒì„±
    stacking_image_path = None
    
    if stacks:
        try:
            stacking_filename = 'stacks_' + file.filename
            stacking_full_path = os.path.join(RESULT_FOLDER, stacking_filename)
            visualize_stacks(filepath, detections, stacks, stacking_full_path)
            stacking_image_path = f"/results/{stacking_filename}"
            print(f"âœ… ìŒ“ì„ ì‹œê°í™” ìƒì„±: {len(stacks)}ê°œ ê·¸ë£¹")
        except Exception as e:
            print(f"âš ï¸ ìŒ“ì„ ì‹œê°í™” ì‹¤íŒ¨: {e}")

    # 6ï¸âƒ£ ê°ì²´ ì¶”ì  ì—…ë°ì´íŠ¸
    tracker = get_tracker()
    tracker.update(detections, file.filename)
    
    problem_objects = tracker.get_problem_objects(min_appearances=2)
    tracking_stats = tracker.get_statistics()
    
    print(f"âœ… ì¶”ì  ì™„ë£Œ: {len(problem_objects)}ê°œ ë°˜ë³µ ë¬¸ì œ")

    # 7ï¸âƒ£ ChatGPT ì¡°ì–¸ ìƒì„± (ì¶”ì  + ìŒ“ì„ ì •ë³´ ë°˜ì˜)
    ai_advice = generate_ai_advice(detections, report["score"])
    
    # ì¶”ì  ì •ë³´ ì¶”ê°€
    if problem_objects:
        chronic_warning = "\n\nğŸ”„ ë°˜ë³µë˜ëŠ” ë¬¸ì œ:\n"
        for prob in problem_objects[:3]:
            chronic_warning += f"- {prob['message']}\n"
        ai_advice += chronic_warning
    
    # ìŒ“ì„ ì •ë³´ ì¶”ê°€
    if stacks:
        stacking_warning = "\n\nâš ï¸ ìŒ“ì„ ì£¼ì˜:\n"
        for stack in stacks[:3]:
            stacking_warning += f"- {stack['message']}\n"
        ai_advice += stacking_warning

    # 8ï¸âƒ£ DB ì €ì¥
    try:
        save_analysis(
            score=report['score'],
            detections=detections,
            report=report,
            image_name=file.filename
        )
        print("âœ… DB ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸ DB ì €ì¥ ì‹¤íŒ¨: {e}")

    # 9ï¸âƒ£ ìµœì¢… ì‘ë‹µ ë°ì´í„° êµ¬ì„±
    response_data = {
        "status": "success",
        "detections": detections,
        "report": report,
        "ai_advice": ai_advice,
        "result_image": f"/results/{os.path.basename(result_img_path)}",
        
        # ğŸ”¥ Segmentation ë°ì´í„°
        "segmentation": {
            "zone_image": zone_visualization_path,
            "area_coverage": area_coverage,
            "detected_areas": room_masks['detected_areas'] if room_masks else []
        },
        
        # ğŸ”¥ ìŒ“ì„ ë°ì´í„°
        "stacking": {
            "stacks": stacks,
            "stacking_image": stacking_image_path,
            "total_stacks": len(stacks),
            "warning": (
                f"âš ï¸ {len(stacks)}ê°œ ê·¸ë£¹ì˜ ë¬¼ê±´ì´ ìŒ“ì—¬ìˆê±°ë‚˜ í¬ê°œì ¸ìˆìŠµë‹ˆë‹¤!"
                if stacks else None
            )
        },
        
        # ğŸ”¥ ì¶”ì  ë°ì´í„°
        "tracking": {
            "chronic_problems": problem_objects,
            "statistics": tracking_stats,
            "warning": (
                f"ğŸ”„ {len(problem_objects)}ê°œ ë¬¼ê±´ì´ ë°˜ë³µì ìœ¼ë¡œ ë¬¸ì œë¥¼ ì¼ìœ¼í‚¤ê³  ìˆì–´ìš”!"
                if problem_objects else None
            )
        }
    }

    if heatmap_path:
        response_data["heatmap_image"] = heatmap_path

    print("âœ… ëª¨ë“  ë¶„ì„ ì™„ë£Œ!")
    return jsonify(response_data)


# ============================================
# ê¸°ì¡´ API ì—”ë“œí¬ì¸íŠ¸ë“¤
# ============================================

@app.route('/history', methods=['GET'])
def get_analysis_history():
    try:
        limit = request.args.get('limit', 10, type=int)
        limit = min(limit, 50)
        history = get_history(limit)
        return jsonify({
            "status": "success",
            "count": len(history),
            "history": history
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/statistics', methods=['GET'])
def get_stats():
    try:
        stats = get_statistics()
        return jsonify({
            "status": "success",
            "statistics": stats
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/tracking/reset', methods=['POST'])
def reset_tracking():
    """ì¶”ì  ì •ë³´ ì´ˆê¸°í™”"""
    try:
        tracker = get_tracker()
        tracker.reset()
        return jsonify({
            "status": "success",
            "message": "ì¶”ì  ì •ë³´ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤."
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/tracking/stats', methods=['GET'])
def get_tracking_stats():
    """ì¶”ì  í†µê³„ ì¡°íšŒ"""
    try:
        tracker = get_tracker()
        stats = tracker.get_statistics()
        problems = tracker.get_problem_objects()
        
        return jsonify({
            "status": "success",
            "statistics": stats,
            "chronic_problems": problems
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/results/<path:filename>')
def serve_result_image(filename):
    return send_from_directory(RESULT_FOLDER, filename)


# ============================================
# ì„œë²„ ì‹¤í–‰
# ============================================
if __name__ == "__main__":
    print("="*50)
    print("ğŸš€ AI ì •ë¦¬ ì •ëˆ ë„ìš°ë¯¸ - ì™„ì „ ê°œì„  ë²„ì „")
    print("="*50)
    print("âœ… Segmentation ê¸°ë°˜ êµ¬ì—­ ë¶„ì„")
    print("âœ… ê°ì²´ ì¶”ì  (ë°˜ë³µ ë¬¸ì œ íƒì§€)")
    print("âœ… ìŒ“ì„/í¬ê°œì§ ìë™ ê°ì§€")
    print("="*50)
    app.run(debug=True, host="0.0.0.0", port=5000)
