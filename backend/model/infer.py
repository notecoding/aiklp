# backend/model/infer.py
"""
ì™„ì „ ê°œì„ ëœ ì¶”ë¡  ëª¨ë“ˆ
- YOLO ê°ì²´ íƒì§€
- Segmentation ê¸°ë°˜ ì •í™•í•œ ìœ„ì¹˜ íŒë‹¨
- ìŒ“ìž„ íŒ¨í„´ íƒì§€
"""
from ultralytics import YOLO
import cv2
import os
import sys

# ëª¨ë“ˆ import
sys.path.append(os.path.dirname(os.path.dirname(__file__)))
from utils.room_segmentation import segment_room_areas, detect_object_location_precise
from utils.stacking_detector import get_stacking_detector

# YOLO ëª¨ë¸ ë¡œë“œ
model = YOLO("yolov8x.pt")

def run_inference(image_path, result_dir):
    """
    ì™„ì „ ê°œì„ ëœ ì´ë¯¸ì§€ ë¶„ì„
    1. ê°ì²´ íƒì§€ (YOLO)
    2. êµ¬ì—­ ë¶„í•  (Segmentation)
    3. ì •í™•í•œ ìœ„ì¹˜ íŒë‹¨
    4. ìŒ“ìž„ íŒ¨í„´ íƒì§€
    
    Returns:
        tuple: (detections, result_path, room_masks, stacks)
    """
    
    # 1ï¸âƒ£ ê¸°ì¡´ ê°ì²´ íƒì§€
    print("ðŸ” Step 1: ê°ì²´ íƒì§€ ì¤‘...")
    results = model.predict(source=image_path, conf=0.4, verbose=False)
    
    detections = []
    img = cv2.imread(image_path)
    
    for box in results[0].boxes:
        cls = int(box.cls[0])
        name = model.names[cls]
        conf = float(box.conf[0])
        x1, y1, x2, y2 = map(int, box.xyxy[0])
        
        detections.append({
            "name": name,
            "conf": round(conf, 2),
            "bbox": [x1, y1, x2, y2]
        })
    
    print(f"âœ… {len(detections)}ê°œ ê°ì²´ íƒì§€ ì™„ë£Œ")
    
    # 2ï¸âƒ£ Segmentation ê¸°ë°˜ êµ¬ì—­ ë¶„í• 
    print("ðŸ” Step 2: êµ¬ì—­ ë¶„í•  ì¤‘...")
    room_masks = None
    try:
        room_masks = segment_room_areas(image_path)
        print(f"âœ… {len(room_masks['detected_areas'])}ê°œ êµ¬ì—­ ë¶„í•  ì™„ë£Œ")
        
        # 3ï¸âƒ£ ê° ê°ì²´ì˜ ì •í™•í•œ ìœ„ì¹˜ íŒë‹¨
        print("ðŸ” Step 3: ìœ„ì¹˜ íŒë‹¨ ì¤‘...")
        for detection in detections:
            precise_location = detect_object_location_precise(
                detection['bbox'], 
                room_masks
            )
            detection['location'] = precise_location
            detection['location_method'] = 'segmentation'
        
        print("âœ… ìœ„ì¹˜ íŒë‹¨ ì™„ë£Œ")
        
    except Exception as e:
        print(f"âš ï¸ Segmentation ì‹¤íŒ¨, ê¸°ë³¸ ë°©ì‹ ì‚¬ìš©: {e}")
        
        # í´ë°±: ê¸°ë³¸ ìœ„ì¹˜ íŒë‹¨
        for detection in detections:
            detection['location'] = _fallback_location(detection['bbox'], img.shape)
            detection['location_method'] = 'fallback'
    
    # 4ï¸âƒ£ ìŒ“ìž„ íŒ¨í„´ íƒì§€
    print("ðŸ” Step 4: ìŒ“ìž„ íŒ¨í„´ íƒì§€ ì¤‘...")
    stacks = []
    try:
        stacking_detector = get_stacking_detector()
        stacks = stacking_detector.detect_stacks(detections)
        print(f"âœ… {len(stacks)}ê°œ ìŒ“ìž„ ê·¸ë£¹ íƒì§€ ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸ ìŒ“ìž„ íƒì§€ ì‹¤íŒ¨: {e}")
    
    # 5ï¸âƒ£ ì‹œê°í™”
    print("ðŸŽ¨ ì‹œê°í™” ìƒì„± ì¤‘...")
    for detection in detections:
        x1, y1, x2, y2 = detection['bbox']
        location = detection.get('location', 'unknown')
        
        # ìœ„ì¹˜ë³„ ìƒ‰ìƒ
        color_map = {
            'floor': (0, 0, 255),        # ë¹¨ê°•
            'bed_surface': (0, 255, 255), # ë…¸ëž‘
            'desk': (0, 255, 0),          # ì´ˆë¡
            'furniture': (255, 128, 0),   # ì£¼í™©
            'wall_shelf': (255, 0, 255),  # ë§ˆì  íƒ€
            'normal': (128, 128, 128)     # íšŒìƒ‰
        }
        color = color_map.get(location, (255, 255, 255))
        
        # ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)
        
        # ë¼ë²¨
        label = f"{detection['name']} ({detection['conf']:.2f})"
        label_with_loc = f"{label} [{location}]"
        
        # ë°°ê²½
        (text_w, text_h), _ = cv2.getTextSize(
            label_with_loc, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1
        )
        cv2.rectangle(img, (x1, y1 - text_h - 5), (x1 + text_w, y1), color, -1)
        
        # í…ìŠ¤íŠ¸
        cv2.putText(img, label_with_loc, (x1, y1 - 5),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
    
    # ìŒ“ìž„ ê·¸ë£¹ í‘œì‹œ
    for stack in stacks:
        x1, y1, x2, y2 = stack['bounding_box']
        stack_color = (0, 0, 255) if stack['severity'] == 'high' else (0, 165, 255)
        
        # ë°˜íˆ¬ëª… ë°•ìŠ¤
        overlay = img.copy()
        cv2.rectangle(overlay, (x1, y1), (x2, y2), stack_color, -1)
        img = cv2.addWeighted(img, 0.7, overlay, 0.3, 0)
        
        # í…Œë‘ë¦¬
        cv2.rectangle(img, (x1, y1), (x2, y2), stack_color, 3)
        
        # ë¼ë²¨
        stack_label = f"STACK: {stack['object']} x{stack['count']}"
        cv2.putText(img, stack_label, (x1 + 5, y1 + 25),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    
    # ê²°ê³¼ ì´ë¯¸ì§€ ì €ìž¥
    result_path = os.path.join(result_dir, os.path.basename(image_path))
    cv2.imwrite(result_path, img)
    print(f"âœ… ê²°ê³¼ ì €ìž¥: {result_path}")
    
    return detections, result_path, room_masks, stacks


def _fallback_location(bbox, img_shape):
    """Segmentation ì‹¤íŒ¨ ì‹œ í´ë°± ìœ„ì¹˜ íŒë‹¨"""
    h, w = img_shape[:2]
    x1, y1, x2, y2 = bbox
    
    if y2 > h * 0.75:
        return 'floor'
    elif y1 < h * 0.3:
        return 'wall_shelf'
    else:
        return 'normal'
